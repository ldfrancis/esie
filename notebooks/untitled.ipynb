{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ad0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39326dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/esie/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcdab20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:06<00:00, 33.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FineWeb-Edu v2\n",
      "Total tokens loaded: 8388608\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/llama-2-7b-hf\", 4096, tokenizer, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fbb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "\n",
    "N = 10 # possible sparsity levels (0.0 - 0.9)\n",
    "S = 3 # number of state features\n",
    "        \n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, model_name:str, num_samples:int, sequence_length:int, target_sparsity:float=0.5)->None:\n",
    "        self.model_name = model_name\n",
    "        self.num_samples = num_samples\n",
    "        self.sequence_length = sequence_length\n",
    "        self.target_sparsity = target_sparsity\n",
    "        self.num_samples = num_samples\n",
    "        self.sequence_length = sequence_length\n",
    "        self.possible_sparsities = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # initialize state\n",
    "        self.load_calibration_data()\n",
    "        self.reset()\n",
    "\n",
    "    def load_calibration_data(self):\n",
    "        # caliberation data\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        self.tokenizer = tokenizer\n",
    "        num_tokens = self.num_samples * self.sequence_length\n",
    "        self.calib_data = get_fineweb_edu(num_tokens, self.sequence_length, tokenizer, train=True)\n",
    "        # self.test_data = get_fineweb_edu(num_tokens, self.sequence_length, tokenizer, train=False)\n",
    "        _, self.test_data = get_w2_data(1, self.sequence_length, tokenizer)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init(self) -> None:\n",
    "        # create model, tokenizer, and calibration data.\n",
    "        # model and tokenizer\n",
    "        model = AutoModelForCausalLM.from_pretrained(self.model_name, dtype=torch.float16, device_map=\"auto\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        # caliberation data\n",
    "        test_data = self.test_data\n",
    "\n",
    "        # env attributes\n",
    "        self.action_mask = torch.ones(N)\n",
    "        self.layers = model.model.layers\n",
    "        self.num_layers = len(self.layers)\n",
    "        self.current_layer = 0\n",
    "        self.global_sparsity = 0.0\n",
    "        self.layer_sparsities = [0.0] * self.num_layers\n",
    "        self.pruning_info = {}\n",
    "\n",
    "        # buffers\n",
    "        self.inps = torch.zeros((self.num_samples, self.sequence_length, model.config.hidden_size), dtype=torch.float16, device=self.device)\n",
    "        self.outs = torch.zeros_like(self.inps)\n",
    "        self.inp_kwargs = {}\n",
    "\n",
    "        # obtain input into the first decoder layer\n",
    "        cache = model.config.use_cache\n",
    "        model.config.use_cache = False\n",
    "        inps = self.inps\n",
    "        inp_kwargs = self.inp_kwargs\n",
    "        class catch_inps(nn.Module):\n",
    "            def __init__(self, module):\n",
    "                super().__init__()\n",
    "                self.module = module\n",
    "                self.num_inps = 0\n",
    "            def forward(self, inp, **kwargs):\n",
    "                nonlocal inps, inp_kwargs\n",
    "                inps[self.num_inps] = inp\n",
    "                inp_kwargs.update(kwargs)\n",
    "                self.num_inps += 1\n",
    "                raise Exception(\"caught inps. Stopping forward pass.\")\n",
    "        self.layers[0] = catch_inps(self.layers[0])\n",
    "        for sample in self.calib_data:\n",
    "            try:\n",
    "                model(sample.to(self.device))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        self.layers[0] = self.layers[0].module\n",
    "        self.inps = inps\n",
    "        self.inp_kwargs = inp_kwargs\n",
    "\n",
    "        # save the log targets to a file for computing the KL divergence later\n",
    "        i_batches = 0\n",
    "        os.makedirs(f\"logs/kl/{self.model_name}\", exist_ok=True)\n",
    "        batch_size = 4\n",
    "        log_probs = []\n",
    "        for j in range(self.num_samples):\n",
    "            if os.path.exists(f\"logs/kl/{self.model_name}/log_targets_{(j//batch_size)}_{batch_size}.pt\"):\n",
    "                i_batches = j // batch_size\n",
    "                continue\n",
    "            sample = test_data[j]\n",
    "            logits = model(sample.to(self.device)).logits\n",
    "            log_probs.append(F.log_softmax(logits.float(), dim=-1).reshape(-1, model.config.vocab_size).cpu())\n",
    "            if j % batch_size == batch_size-1:\n",
    "                log_probs = torch.cat(log_probs, dim=0).cpu()\n",
    "                torch.save(log_probs, f\"logs/kl/{self.model_name}/log_targets_{i_batches}_{batch_size}.pt\")\n",
    "                log_probs = []\n",
    "            elif j == self.num_samples - 1 and len(log_probs) > 0:\n",
    "                log_probs = torch.cat(log_probs, dim=0).cpu()\n",
    "                torch.save(log_probs, f\"logs/kl/{self.model_name}/log_targets_{i_batches}_{batch_size}.pt\")\n",
    "            i_batches = j // batch_size\n",
    "        # print(f\"Saved {i_batches+1} batches of log probabilities for KL divergence computation.\")\n",
    "        # create a dataloader for computing KL divergence later\n",
    "        model_name = self.model_name\n",
    "        class KLDataset(torch.utils.data.Dataset):\n",
    "            def __init__(self):\n",
    "                self.path_format = f\"logs/kl/{model_name}\"+\"/log_targets_{}_{}.pt\"\n",
    "            def __len__(self):\n",
    "                return i_batches + 1\n",
    "            def __getitem__(self, idx):\n",
    "                nonlocal batch_size\n",
    "                samples = torch.cat(test_data[idx*batch_size:(idx+1)*batch_size], dim=0)\n",
    "                log_probs = torch.load(self.path_format.format(idx, batch_size))\n",
    "                return samples, log_probs\n",
    "        self.kl_dataloader = torch.utils.data.DataLoader(KLDataset(), batch_size=1, shuffle=False)\n",
    "        # print(f\"KL dataloader with {len(self.kl_dataloader)} batches created.\")\n",
    "        model.config.use_cache = cache\n",
    "\n",
    "    def prune_layer(self, layer_idx:int, sparsity:float)->None:\n",
    "        if layer_idx in self.pruning_info:\n",
    "            raise Exception(f\"Layer {layer_idx} already pruned. Skipping.\")\n",
    "        \n",
    "        layer = self.layers[layer_idx]\n",
    "        sublayers = {name: module for name, module in layer.named_modules() if isinstance(module, nn.Linear)}\n",
    "        wrapped_layers = {}\n",
    "        for name, sublayer in sublayers.items():\n",
    "            wrapped_layers[name] = WrappedGPT(sublayer)\n",
    "\n",
    "        # obtain the input activations to each sublayer, computing the feature-wise norms\n",
    "        def add_batch(name):\n",
    "            def tmp(_, inp, out):\n",
    "                wrapped_layers[name].add_batch(inp[0].data, out.data)\n",
    "            return tmp\n",
    "        handles = []\n",
    "        for name in wrapped_layers:\n",
    "            handles.append(sublayers[name].register_forward_hook(add_batch(name)))\n",
    "        for j in range(self.num_samples):\n",
    "            self.outs[j] = layer(self.inps[j].unsqueeze(0), **self.inp_kwargs)[0]\n",
    "        for h in handles:\n",
    "            h.remove()\n",
    "        \n",
    "        for name in sublayers:\n",
    "            wrapped_layers[name].prune(sparsity)\n",
    "            wrapped_layers[name].clean()\n",
    "\n",
    "        # outputs after pruning\n",
    "        for j in range(self.num_samples):\n",
    "            with torch.no_grad():\n",
    "                self.outs[j] = layer(self.inps[j].unsqueeze(0), **self.inp_kwargs)[0]\n",
    "\n",
    "        # the output from this layer should be the input to the next layer\n",
    "        self.inps, self.outs = self.outs, self.inps\n",
    "\n",
    "        # done pruning this layer. Prepare some info about this layer's pruning\n",
    "        obtained_sparsity = np.mean([l.weight.data.eq(0).float().mean().item() for l in sublayers.values()]).item()\n",
    "        info = {\n",
    "            \"layer\": layer_idx,\n",
    "            \"layer_target_sparsity\": sparsity,\n",
    "            \"layer_obtained_sparsity\": obtained_sparsity,\n",
    "        }\n",
    "        self.pruning_info[layer_idx] = info\n",
    "\n",
    "    def reset(self) -> Dict[str, torch.Tensor]:\n",
    "        if hasattr(self, \"inps\"):\n",
    "            del self.inps, self.outs, self.inp_kwargs\n",
    "            del self.kl_dataloader\n",
    "            del self.model, self.tokenizer\n",
    "        torch.cuda.empty_cache()\n",
    "        self.init()\n",
    "        return self.get_state()\n",
    "\n",
    "    def get_state(self) -> Dict[str, torch.Tensor]:\n",
    "        s = [self.global_sparsity, self.target_sparsity, self.current_layer / self.num_layers]\n",
    "        if self.current_layer == 0:\n",
    "            mask = [1] * len(self.possible_sparsities)\n",
    "        else:\n",
    "            mask = [1 if (sum(self.layer_sparsities[:self.current_layer]) + s) / self.current_layer <= self.target_sparsity else 0 for s in self.possible_sparsities]\n",
    "        state = {\n",
    "            \"state\": torch.tensor(s, dtype=torch.float32),\n",
    "            \"action_mask\": torch.tensor(mask, dtype=torch.float32)\n",
    "        }\n",
    "        return state\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, action:int)->Tuple[Dict[str, torch.Tensor], float, bool, Dict[str, object]]:\n",
    "        sparsity = self.possible_sparsities[action]\n",
    "        self.prune_layer(self.current_layer, sparsity)\n",
    "        # update global sparsity\n",
    "        self.layer_sparsities[self.current_layer] = sparsity\n",
    "        self.current_layer += 1\n",
    "        self.global_sparsity = np.mean(self.layer_sparsities[:self.current_layer])\n",
    "        # compute reward\n",
    "        reward = 0\n",
    "        done = self.current_layer == self.num_layers\n",
    "        if done:\n",
    "            # compute KL divergence between the pruned and unpruned model.\n",
    "            # the logits have been saved to a file during initialization.\n",
    "            running_kl = 0.0\n",
    "            total_logprobs = 0\n",
    "            # for batch in self.kl_dataloader:\n",
    "            #     inps, target_log_probs = [batch[0].squeeze(0), batch[1].squeeze(0)]\n",
    "            #     logits = self.model(inps.to(self.device)).logits.reshape(-1, self.model.config.vocab_size)\n",
    "            #     log_probs = F.log_softmax(logits.float(), dim=-1)\n",
    "            #     kl = F.kl_div(log_probs, target_log_probs.to(self.device), reduction=\"batchmean\", log_target=True).item()\n",
    "            #     running_kl *= (total_logprobs / (total_logprobs + target_log_probs.numel()))\n",
    "            #     running_kl += (target_log_probs.numel() / (total_logprobs + target_log_probs.numel())) * kl\n",
    "            #     total_logprobs += target_log_probs.numel()\n",
    "            #     del target_log_probs, logits, kl\n",
    "            #     torch.cuda.empty_cache()\n",
    "            reward = running_kl\n",
    "            reward = eval_ppl(self.model, self.test_data, self.sequence_length, device=self.device)\n",
    "\n",
    "        return self.get_state(), reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0b6c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL Agent\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class RLActor(nn.Module):\n",
    "    def __init__(self, state_size:int, action_size:int, device:str=\"cuda\"):\n",
    "        super(RLActor, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.device = device\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(S+N, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.head = nn.Linear(256, N)\n",
    "        self.uniform_init()\n",
    "\n",
    "    def forward(self, state:Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        s = state[\"state\"]\n",
    "        action_mask = state[\"action_mask\"]\n",
    "        large_neg = torch.finfo(s.dtype).min\n",
    "        x = torch.cat([s, action_mask], dim=-1).to(self.device)\n",
    "        x = self.base(x)\n",
    "        logits = self.head(x)\n",
    "        logits = torch.where(action_mask.to(self.device) == 1, logits, large_neg)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        dist = torch.distributions.Categorical(probs)\n",
    "        return dist\n",
    "\n",
    "    def uniform_init(self):\n",
    "        bias = self.head.bias.data.detach().clone()\n",
    "        bias = torch.ones_like(bias)*(1/self.action_size)\n",
    "        self.head.bias.data.copy_(bias)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def act(self, state:Dict[str, torch.Tensor], deterministic=False) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        state = {k: v.unsqueeze(0) for k, v in state.items()}\n",
    "        dist = self(state)\n",
    "        action = dist.sample() if not deterministic else dist.mode\n",
    "        log_prob = dist.log_prob(action)\n",
    "        return action, log_prob\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_size:int, action_size:int):\n",
    "        super(Critic, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(S, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, state:torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca1b389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLLearner:\n",
    "    def __init__(self, model: nn.Module, gamma: float = 1.0, lr=1e-4, device: str = \"cuda\"):\n",
    "        self.model = model\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "    def __call__(self, trajectories):\n",
    "        R = 0\n",
    "        returns = []\n",
    "        for _, _, reward, log_prob in reversed(trajectories):\n",
    "            R = reward + self.gamma * R\n",
    "            returns.insert(0, R)\n",
    "        returns = torch.tensor(returns).to(self.device)\n",
    "        baseline = 6.0\n",
    "        returns = (returns - baseline)\n",
    "        bs = 4\n",
    "        loss = 0\n",
    "        self.optimizer.zero_grad()\n",
    "        scale = 1/len(returns)\n",
    "        for i in range(0, len(returns), bs):\n",
    "            j = min(i+bs, len(returns))\n",
    "            trans = trajectories[i:j]\n",
    "            r = returns[i:j]\n",
    "            x = {\n",
    "                    \"state\": torch.stack([t[0][\"state\"] for t in trans], dim=0).to(self.device),\n",
    "                    \"action_mask\": torch.stack([t[0][\"action_mask\"] for t in trans], dim=0).to(self.device)\n",
    "            }\n",
    "            a = torch.cat([t[1] for t in trans]).to(self.device)\n",
    "            dist = self.model(x)\n",
    "            loss += (scale)*(dist.log_prob(a) * r).sum()\n",
    "        loss.backward()\n",
    "        # for (state, action, _, log_prob), R in zip(trajectories, returns):\n",
    "        #     # self.model(state[])\n",
    "        #     print(log_prob)\n",
    "        #     policy_loss.append(log_prob * R)\n",
    "        # self.optimizer.zero_grad()\n",
    "        # policy_loss = torch.cat(policy_loss).sum()\n",
    "        # policy_loss.backward()\n",
    "        # self.optimizer.step()\n",
    "        # return policy_loss.item()\n",
    "        return loss.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71675823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorRollout:\n",
    "    def __init__(self, env: Environment, actor: RLActor):\n",
    "        self.env = env\n",
    "        self.actor = actor\n",
    "\n",
    "    def __call__(self):\n",
    "        state = self.env.reset()\n",
    "        done = False\n",
    "        trajectories = []\n",
    "        while not done:\n",
    "            action, log_prob = self.actor.act(state)\n",
    "            next_state, reward, done, _ = self.env.step(action.item())\n",
    "            trajectories.append((state, action, reward, log_prob))\n",
    "            state = next_state\n",
    "        return trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdef09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, env: Environment, actor: RLActor, gamma: float = 0.99, lr: float = 1e-4):\n",
    "        self.env = env\n",
    "        self.actor = actor\n",
    "        self.learner = RLLearner(actor, gamma=gamma, lr=lr, device=actor.device)\n",
    "        self.rollout = ActorRollout(env, actor)\n",
    "\n",
    "    def __call__(self, num_episodes:int=100):\n",
    "        for episode in range(num_episodes):\n",
    "            start_time = time.time()\n",
    "            trajectories = self.rollout()\n",
    "            loss = self.learner(trajectories)\n",
    "            end_time = time.time()\n",
    "            kl = trajectories[-1][2]\n",
    "            print(f\"Episode {episode+1}/{num_episodes}, Loss: {loss:.4f}, KL:{kl}, Time: {end_time - start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "363cb7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FineWeb-Edu v2\n",
      "Total tokens loaded: 524288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "environment = Environment(model_name, num_samples=128, sequence_length=4096, target_sparsity=0.5)\n",
    "actor = RLActor(state_size=S, action_size=N, device=\"cuda\")\n",
    "actor.to(actor.device)\n",
    "trainer = Trainer(environment, actor, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c378bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/20, Loss: -30.4306, KL:22.85381317138672, Time: 108.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2/20, Loss: -1.1163, KL:7.542420387268066, Time: 110.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3/20, Loss: -19.6847, KL:17.155426025390625, Time: 94.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4/20, Loss: -19.8593, KL:17.34784698486328, Time: 112.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5/20, Loss: -4.1235, KL:9.071385383605957, Time: 106.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6/20, Loss: -1.3517, KL:7.661917686462402, Time: 97.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7/20, Loss: -643.3914, KL:332.116943359375, Time: 111.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8/20, Loss: -5.7742, KL:9.996315002441406, Time: 98.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9/20, Loss: -8.4242, KL:11.264843940734863, Time: 89.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10/20, Loss: 0.0755, KL:6.900660037994385, Time: 111.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 11/20, Loss: -5.9629, KL:10.077919006347656, Time: 106.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 12/20, Loss: -2.9005, KL:8.48875617980957, Time: 91.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 13/20, Loss: -4.8548, KL:9.553827285766602, Time: 106.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 14/20, Loss: -8.0569, KL:11.159964561462402, Time: 105.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 15/20, Loss: -5.3118, KL:9.735267639160156, Time: 89.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 16/20, Loss: -22.6391, KL:18.800804138183594, Time: 112.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 17/20, Loss: -1.5397, KL:7.766565322875977, Time: 108.86s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 18/20, Loss: -13.5594, KL:13.879164695739746, Time: 90.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 19/20, Loss: -4.0738, KL:9.069145202636719, Time: 101.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20/20, Loss: -11.4958, KL:12.84262466430664, Time: 111.72s\n"
     ]
    }
   ],
   "source": [
    "trainer(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad79a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/llama-2-7b-hf\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, dtype=torch.float16, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "w2_train_data, w2_test_data = get_w2_data(128, 4096, tokenizer)\n",
    "\n",
    "num_tokens = 2**23\n",
    "fw_train_data = get_fineweb_edu(num_tokens, 4096, tokenizer, train=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_default(model, fw_train_data, 0.5, theta1=0.42, theta2=0.51, theta3=0.38, is_sparsegpt=True, device=torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d7644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ppl(model, w2_test_data, 4096,  bs=1, device=\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
