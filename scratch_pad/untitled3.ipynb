{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605006bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c18c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/esie/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Dict, Tuple\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import os\n",
    "try:\n",
    "    import wandb\n",
    "except ImportError:\n",
    "    print(\"wandb not installed. WandBLogger will not work.\")\n",
    "    wandb = None\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c96ab53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Environment:\n",
    "    def __init__(self, model_name:str, num_samples:int, sequence_length:int, target_sparsity:float=0.5)->None:\n",
    "        self.model_name = model_name\n",
    "        self.num_samples = num_samples\n",
    "        self.sequence_length = sequence_length\n",
    "        self.target_sparsity = target_sparsity\n",
    "        self.num_samples = num_samples\n",
    "        self.sequence_length = sequence_length\n",
    "        self.possible_sparsities = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "        self.device = device if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # initialize state\n",
    "        self.load_calibration_data()\n",
    "        self.reset()\n",
    "\n",
    "    def load_calibration_data(self):\n",
    "        # caliberation data\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        self.tokenizer = tokenizer\n",
    "        num_tokens = self.num_samples * self.sequence_length\n",
    "        self.calib_data = get_fineweb_edu(num_tokens, self.sequence_length, tokenizer, train=True)\n",
    "        # self.test_data = get_fineweb_edu(num_tokens, self.sequence_length, tokenizer, train=False)\n",
    "        _, self.test_data = get_w2_data(self.num_samples, self.sequence_length, tokenizer)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init(self) -> None:\n",
    "        # create model, tokenizer, and calibration data.\n",
    "        # model and tokenizer\n",
    "        model = AutoModelForCausalLM.from_pretrained(self.model_name, dtype=torch.float16, attn_implementation=\"flash_attention_2\", device_map=\"cpu\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        # caliberation data\n",
    "        test_data = self.test_data\n",
    "\n",
    "        # env attributes\n",
    "        self.action_mask = torch.ones(N)\n",
    "        self.layers = model.model.layers\n",
    "        self.num_layers = len(self.layers)\n",
    "        self.current_layer = 0\n",
    "        self.global_sparsity = 0.0\n",
    "        self.layer_sparsities = [0.0] * self.num_layers\n",
    "        self.pruning_info = {}\n",
    "\n",
    "        # buffers\n",
    "        self.inps = torch.zeros((self.num_samples, self.sequence_length, model.config.hidden_size), dtype=torch.float16, device=self.device)\n",
    "        self.outs = torch.zeros_like(self.inps)\n",
    "        self.inp_kwargs = {}\n",
    "\n",
    "        # obtain input into the first decoder layer\n",
    "        cache = model.config.use_cache\n",
    "        model.config.use_cache = False\n",
    "        inps = self.inps\n",
    "        inp_kwargs = self.inp_kwargs\n",
    "        class catch_inps(nn.Module):\n",
    "            def __init__(self, module):\n",
    "                super().__init__()\n",
    "                self.module = module\n",
    "                self.num_inps = 0\n",
    "            def forward(self, inp, **kwargs):\n",
    "                nonlocal inps, inp_kwargs\n",
    "                inps[self.num_inps] = inp\n",
    "                inp_kwargs.update(kwargs)\n",
    "                self.num_inps += 1\n",
    "                raise Exception(\"caught inps. Stopping forward pass.\")\n",
    "        self.layers[0] = catch_inps(self.layers[0])\n",
    "        for sample in self.calib_data:\n",
    "            try:\n",
    "                model(sample.to(self.device))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        self.layers[0] = self.layers[0].module\n",
    "        self.inps = inps\n",
    "        self.inp_kwargs = inp_kwargs\n",
    "\n",
    "        # save the log targets to a file for computing the KL divergence later\n",
    "        i_batches = 0\n",
    "        os.makedirs(f\"logs/kl/{self.model_name}\", exist_ok=True)\n",
    "        batch_size = 4\n",
    "        log_probs = []\n",
    "        for j in range(self.num_samples):\n",
    "            continue\n",
    "            if os.path.exists(f\"logs/kl/{self.model_name}/log_targets_{(j//batch_size)}_{batch_size}.pt\"):\n",
    "                i_batches = j // batch_size\n",
    "                continue\n",
    "            sample = test_data[j]\n",
    "            logits = model(sample.to(self.device)).logits\n",
    "            log_probs.append(F.log_softmax(logits.float(), dim=-1).reshape(-1, model.config.vocab_size).cpu())\n",
    "            if j % batch_size == batch_size-1:\n",
    "                log_probs = torch.cat(log_probs, dim=0).cpu()\n",
    "                torch.save(log_probs, f\"logs/kl/{self.model_name}/log_targets_{i_batches}_{batch_size}.pt\")\n",
    "                print(f\"Saved logs/kl/{self.model_name}/log_targets_{i_batches}_{batch_size}.pt\")\n",
    "                log_probs = []\n",
    "            elif j == self.num_samples - 1 and len(log_probs) > 0:\n",
    "                log_probs = torch.cat(log_probs, dim=0).cpu()\n",
    "                torch.save(log_probs, f\"logs/kl/{self.model_name}/log_targets_{i_batches}_{batch_size}.pt\")\n",
    "                print(f\"Saved logs/kl/{self.model_name}/log_targets_{i_batches}_{batch_size}.pt\")\n",
    "            i_batches = j // batch_size\n",
    "            \n",
    "        # create a dataloader for computing KL divergence later\n",
    "        model_name = self.model_name\n",
    "        class KLDataset(torch.utils.data.Dataset):\n",
    "            def __init__(self):\n",
    "                self.path_format = f\"logs/kl/{model_name}\"+\"/log_targets_{}_{}.pt\"\n",
    "            def __len__(self):\n",
    "                return i_batches + 1\n",
    "            def __getitem__(self, idx):\n",
    "                nonlocal batch_size\n",
    "                samples = torch.cat(test_data[idx*batch_size:(idx+1)*batch_size], dim=0)\n",
    "                log_probs = torch.load(self.path_format.format(idx, batch_size))\n",
    "                return samples, log_probs\n",
    "        self.kl_dataloader = torch.utils.data.DataLoader(KLDataset(), batch_size=1, shuffle=False)\n",
    "        # print(f\"KL dataloader with {len(self.kl_dataloader)} batches created.\")\n",
    "        model.config.use_cache = cache\n",
    "\n",
    "    def reset(self) -> Dict[str, torch.Tensor]:\n",
    "        if hasattr(self, \"inps\"):\n",
    "            del self.inps, self.outs, self.inp_kwargs\n",
    "            del self.kl_dataloader\n",
    "            del self.model, self.tokenizer\n",
    "        torch.cuda.empty_cache()\n",
    "        self.init()\n",
    "        return self.get_state(), {}\n",
    "\n",
    "    def get_state(self) -> Dict[str, torch.Tensor]:\n",
    "        s = [self.global_sparsity, self.target_sparsity, self.current_layer / self.num_layers]\n",
    "\n",
    "        # action mask\n",
    "        # ensure not to exceed target sparsity\n",
    "        mask1 = [1 if (sum(self.layer_sparsities[:self.current_layer]) + s) / (self.num_layers) <= self.target_sparsity else 0 for s in self.possible_sparsities]\n",
    "        # ensure not to make target sparsity impossible to reach\n",
    "        mask2 = [1 if (sum(self.layer_sparsities[:self.current_layer]) + s + 0.9*(self.num_layers - (self.current_layer+1)))/self.num_layers >= self.target_sparsity else 0 for s in self.possible_sparsities]\n",
    "        mask = [m1*m2 for m1, m2 in zip(mask1, mask2)]\n",
    "        \n",
    "        state = {\n",
    "            \"state\": torch.tensor(s, dtype=torch.float32),\n",
    "            \"action_mask\": torch.tensor(mask, dtype=torch.float32)\n",
    "        }\n",
    "        return state\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, action:int)->Tuple[Dict[str, torch.Tensor], float, bool, Dict[str, object]]:\n",
    "        sparsity = self.possible_sparsities[action]\n",
    "        # self.prune_layer(self.current_layer, sparsity)\n",
    "        # update global sparsity\n",
    "        self.layer_sparsities[self.current_layer] = sparsity\n",
    "        self.current_layer += 1\n",
    "        self.global_sparsity = np.mean(self.layer_sparsities[:self.current_layer])\n",
    "        # compute reward\n",
    "        reward = 0\n",
    "        done = self.current_layer == self.num_layers\n",
    "        if done:\n",
    "            # compute KL divergence between the pruned and unpruned model.\n",
    "            # the logits have been saved to a file during initialization.\n",
    "            running_kl = 0.0\n",
    "            total_logprobs = 0\n",
    "            weights_dir = os.path.join(f\"logs/sparse_weights/{self.model_name.split('/')[-1]}\", \"sparsegpt\")\n",
    "            load_layers(self.model, self.layer_sparsities, weights_dir)\n",
    "            # for batch in self.kl_dataloader:\n",
    "            #     inps, target_log_probs = [batch[0].squeeze(0), batch[1].squeeze(0)]\n",
    "            #     logits = self.model(inps.to(self.device)).logits.reshape(-1, self.model.config.vocab_size)\n",
    "            #     log_probs = F.log_softmax(logits.float(), dim=-1)\n",
    "            #     kl = F.kl_div(log_probs, target_log_probs.to(self.device), reduction=\"batchmean\", log_target=True).item()\n",
    "            #     running_kl *= (total_logprobs / (total_logprobs + target_log_probs.numel()))\n",
    "            #     running_kl += (target_log_probs.numel() / (total_logprobs + target_log_probs.numel())) * kl\n",
    "            #     total_logprobs += target_log_probs.numel()\n",
    "            #     del target_log_probs, logits, kl\n",
    "            #     torch.cuda.empty_cache()\n",
    "            # reward = -running_kl\n",
    "            self.model.to(self.device)\n",
    "            reward = -eval_ppl(self.model, self.test_data, self.sequence_length, device=self.device)\n",
    "            \n",
    "\n",
    "        return self.get_state(), reward, done, False, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b70feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebugEnvironment:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.cur_layer = 0\n",
    "        self.n_layers = 5\n",
    "        self.actions = []\n",
    "        return self.get_state(), {}\n",
    "\n",
    "    def get_state(self):\n",
    "        state = {\n",
    "            \"state\": torch.tensor([self.cur_layer / self.n_layers]*3, dtype=torch.float32),\n",
    "            \"action_mask\": torch.ones(N, dtype=torch.float32)\n",
    "        }\n",
    "        # state = torch.tensor([self.cur_layer / self.n_layers]*3, dtype=torch.float32)\n",
    "        return state\n",
    "\n",
    "    def step(self, action:int):\n",
    "        self.actions.append(action)\n",
    "        self.cur_layer += 1\n",
    "        done = self.cur_layer == self.n_layers\n",
    "        reward = 0\n",
    "        if done:\n",
    "            target = [1,2,3,0,3]\n",
    "            diff = 0\n",
    "            for i in range(len(self.actions)):\n",
    "                diff += abs(self.actions[i] - target[i])\n",
    "            reward = max(0, 10 - diff)\n",
    "        \n",
    "        return self.get_state(), reward*100, done, False, {}\n",
    "\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self, state_size:int, action_size:int, device:str=device):\n",
    "        super(Policy, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.device = device\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(state_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.head = nn.Linear(256, action_size)\n",
    "        self.uniform_init()\n",
    "\n",
    "    def to(self, device:Optional[str]=None):\n",
    "        if device is None:\n",
    "            device = self.device\n",
    "        self.device = device\n",
    "        return super().to(device)\n",
    "\n",
    "    def forward(self, state:Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        large_neg = torch.finfo(state.dtype).min\n",
    "        action_mask = state[:, -self.action_size:]\n",
    "\n",
    "        x = self.base(state)\n",
    "        logits = self.head(x)\n",
    "        logits = torch.where(action_mask.to(self.device) == 1, logits, large_neg)\n",
    "        \n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        dist = torch.distributions.Categorical(probs)\n",
    "        return dist\n",
    "\n",
    "    def uniform_init(self):\n",
    "        bias = self.head.bias.data.detach().clone()\n",
    "        bias = torch.ones_like(bias)*(1/self.action_size)\n",
    "        self.head.bias.data.copy_(bias)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def act(self, state:Dict[str, torch.Tensor], deterministic=False) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        if len(state.shape) == 1:\n",
    "            state = state.unsqueeze(0)\n",
    "        dist = self(state)\n",
    "        action = dist.sample() if not deterministic else dist.mode\n",
    "        log_prob = dist.log_prob(action)\n",
    "        return action, log_prob\n",
    "\n",
    "\n",
    "class Value(nn.Module):\n",
    "    def __init__(self, state_size:int, device:str):\n",
    "        super(Value, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(state_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        self.device = device\n",
    "\n",
    "    def to(self, device:Optional[str]=None):\n",
    "        if device is None:\n",
    "            device = self.device\n",
    "        self.device = device\n",
    "        return super().to(device)\n",
    "\n",
    "    def forward(self, state:torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(state)\n",
    "\n",
    "\n",
    "class PolicyValue:\n",
    "    def __init__(self, policy_model: nn.Module, value_model: nn.Module):\n",
    "        self.policy_model = policy_model\n",
    "        self.value_model = value_model\n",
    "        self.device = policy_model.device\n",
    "\n",
    "    def to(self, device:Optional[str]=None):\n",
    "        if device is None:\n",
    "            device = self.device\n",
    "        self.device = device\n",
    "        self.policy_model.to(device)\n",
    "        self.value_model.to(device)\n",
    "        return self\n",
    "\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        dist = self.policy_model(x)\n",
    "        value = self.value_model(x)\n",
    "        if action is None:\n",
    "            action = dist.sample()\n",
    "        return action, dist.log_prob(action), dist.entropy(), value\n",
    "\n",
    "    def get_value(self, x):\n",
    "        return self.value_model(x)\n",
    "    \n",
    "    def get_dist(self, x):\n",
    "        return self.policy_model(x)\n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def process_trajectory(trajectory, gamma, lam, device):\n",
    "    lastgaelam = 0\n",
    "    steps = len(trajectory)\n",
    "    advantages = torch.zeros(steps).to(device)\n",
    "\n",
    "    states, actions, rewards, log_probs, values = [], [], [], [], []\n",
    "    for trans in trajectory:\n",
    "        state, action, reward, log_prob, value = trans\n",
    "        states.append(torch.tensor(state).to(device))\n",
    "        actions.append(torch.tensor(action).to(device))\n",
    "        rewards.append(torch.tensor(reward).to(device))\n",
    "        log_probs.append(torch.tensor(log_prob).to(device))\n",
    "        values.append(torch.tensor(value).to(device))\n",
    "\n",
    "    values = torch.cat(values)\n",
    "    states = torch.stack(states, dim=0)\n",
    "    actions = torch.cat(actions)\n",
    "    log_probs = torch.cat(log_probs)\n",
    "    rewards = torch.stack(rewards)\n",
    "\n",
    "    for t in reversed(range(steps)):\n",
    "        if t == steps - 1:\n",
    "            nextnonterminal = 0.0\n",
    "            nextvalue = 0.0\n",
    "        else:\n",
    "            nextnonterminal = 1.0\n",
    "            nextvalue = values[t+1]\n",
    "        delta = rewards[t] + gamma * nextvalue * nextnonterminal - values[t]\n",
    "        advantages[t] = lastgaelam = delta + gamma * lam * nextnonterminal * lastgaelam\n",
    "        \n",
    "    returns = advantages + values.squeeze()\n",
    "\n",
    "    return states, actions, log_probs, values, returns, advantages\n",
    "\n",
    "\n",
    "def process_trajectories(trajectories, gamma, lam, device):\n",
    "    states, actions, log_probs, values, returns, advantages = [], [], [], [], [], []\n",
    "    for trajectory in trajectories:\n",
    "        s, a, lp, v, r, adv = process_trajectory(trajectory, gamma, lam, device)\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        log_probs.append(lp)\n",
    "        values.append(v)\n",
    "        returns.append(r)\n",
    "        advantages.append(adv)\n",
    "    states = torch.cat(states, dim=0)\n",
    "    actions = torch.cat(actions, dim=0)\n",
    "    log_probs = torch.cat(log_probs, dim=0)\n",
    "    values = torch.cat(values, dim=0)\n",
    "    returns = torch.cat(returns, dim=0)\n",
    "    advantages = torch.cat(advantages, dim=0)\n",
    "    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "    return states, actions, log_probs, values, returns, advantages\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.step = 0\n",
    "\n",
    "    def log(self, metrics:Dict[str, float], step:Optional[int]=None):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def term(self, *args):\n",
    "        print(*args)\n",
    "\n",
    "\n",
    "class WandBLogger(Logger):\n",
    "    def __init__(self, entity:str=\"ldfrancis\", project_name:str=\"RLPress\"):\n",
    "        super().__init__()\n",
    "        wandb.init(project=project_name, entity=entity)\n",
    "\n",
    "    def log(self, metrics:Dict[str, float], step:Optional[int]=None):\n",
    "        if step is None:\n",
    "            step = self.step\n",
    "            self.step += 1\n",
    "        wandb.log(metrics, step=step)\n",
    "\n",
    "\n",
    "class TerminalLogger(Logger):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def log(self, metrics:Dict[str, float], step:Optional[int]=None):\n",
    "        if step is None:\n",
    "            step = self.step\n",
    "            self.step += 1\n",
    "        print(f\"Step {step}:\")\n",
    "        for k, v in metrics.items():\n",
    "            print(f\"\\t{k} : {v}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "class RLLearner:\n",
    "    def __init__(self, policy_n_value:PolicyValue, gamma: float = 0.99, lam: float = 0.95, lr=1e-4, device: str = device):\n",
    "        self.policy_n_value = policy_n_value\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.device = device\n",
    "        self.policy_optimizer = torch.optim.Adam(self.policy_n_value.policy_model.parameters(), lr=lr)\n",
    "        self.value_optimizer = torch.optim.Adam(self.policy_n_value.value_model.parameters(), lr=1e-5)\n",
    "        self.global_step = 0\n",
    "\n",
    "    def __call__(self, trajectories, epochs:int=5):\n",
    "        states, actions, log_probs, values, returns, advantages = process_trajectories(trajectories, self.gamma, lam=0.95, device=self.device)\n",
    "        max_grad_norm = 0.5\n",
    "        target_kl = 0.01\n",
    "        self.global_step += len(states)\n",
    "       \n",
    "        bs = 32\n",
    "        inds = np.arange(0, len(states))\n",
    "        clip_coef = 0.2\n",
    "        clipfracs = []\n",
    "        \n",
    "        policy_losses = []\n",
    "        value_losses = []\n",
    "        entropy_losses = []\n",
    "        approx_kls = []\n",
    "        old_approx_kls = []\n",
    "        grad_steps = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            stop_updates = False\n",
    "            np.random.shuffle(inds)\n",
    "            # self.policy_optimizer.zero_grad(); self.value_optimizer.zero_grad()\n",
    "            for start in range(0, len(states), bs):\n",
    "                end = min(start+bs, len(states))\n",
    "                b_inds = inds[start:end]\n",
    "\n",
    "                x = states[b_inds].to(self.device)\n",
    "                a = actions[b_inds].to(self.device)\n",
    "\n",
    "                dist = self.policy_n_value.get_dist(x)\n",
    "                newlogprob = dist.log_prob(a)\n",
    "                entropy = dist.entropy()\n",
    "                newvalue = self.policy_n_value.get_value(x)\n",
    "                \n",
    "                logratio = newlogprob - log_probs[b_inds].to(self.device)\n",
    "                ratio = logratio.exp()\n",
    "\n",
    "                # Policy loss\n",
    "                pg_obj1 = advantages[b_inds] * ratio\n",
    "                pg_obj2 = advantages[b_inds] * torch.clamp(ratio, 1 - clip_coef, 1 + clip_coef)\n",
    "                pg_loss = -torch.min(pg_obj1, pg_obj2).mean()\n",
    "\n",
    "                # Value loss\n",
    "                v_loss = 0.5 * ((newvalue - returns[b_inds])**2).mean()\n",
    "\n",
    "                # Entropy loss\n",
    "                entropy_loss = -entropy.mean()\n",
    "\n",
    "                # Combined loss\n",
    "                loss = pg_loss + 0.1 * entropy_loss\n",
    "\n",
    "                self.policy_optimizer.zero_grad(); self.value_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                v_loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.policy_n_value.value_model.parameters(), max_grad_norm)\n",
    "                nn.utils.clip_grad_norm_(self.policy_n_value.policy_model.parameters(), max_grad_norm)\n",
    "                self.policy_optimizer.step(); self.value_optimizer.step()\n",
    "\n",
    "                # Approx kl\n",
    "                with torch.no_grad():\n",
    "                    old_approx_kl = (-logratio).mean()\n",
    "                    approx_kl = (ratio - 1 - logratio).mean()\n",
    "                    clipfracs += [((ratio > (1 + clip_coef)) | (ratio < (1 - clip_coef))).float().mean().item()]\n",
    "\n",
    "                grad_steps += 1\n",
    "                policy_losses += [pg_loss.item()]\n",
    "                value_losses += [v_loss.item()]\n",
    "                entropy_losses += [entropy_loss.item()]\n",
    "                approx_kls += [approx_kl.item()]\n",
    "                old_approx_kls += [old_approx_kl.item()]\n",
    "\n",
    "                # if approx_kl > target_kl:\n",
    "                #     stop_updates = True\n",
    "                #     break\n",
    "            # self.policy_optimizer.step(); self.value_optimizer.step()\n",
    "            if stop_updates:\n",
    "                break\n",
    "\n",
    "        learner_results = {\n",
    "            \"learner/losses/policy_loss\": np.mean(policy_losses) if policy_losses else 0,\n",
    "            \"learner/losses/value_loss\": np.mean(value_losses) if value_losses else 0,\n",
    "            \"learner/losses/entropy_loss\": np.mean(entropy_losses) if entropy_losses else 0,\n",
    "            \"learner/losses/approx_kls\": np.mean(approx_kls) if approx_kls else 0,\n",
    "            \"learner/losses/old_approx_kls\": np.mean(old_approx_kls) if old_approx_kls else 0,\n",
    "            \"learner/losses/clipfrac\": np.mean(clipfracs),\n",
    "            \"global_step\": self.global_step,\n",
    "        }\n",
    "\n",
    "        return learner_results\n",
    "        \n",
    "\n",
    "class PolicyValueRollout:\n",
    "    def __init__(self, env: DebugEnvironment, policy_n_value: PolicyValue):\n",
    "        self.env = env\n",
    "        self.policy_n_value = policy_n_value\n",
    "        self.policy_model = policy_n_value.policy_model\n",
    "        self.value_model = policy_n_value.value_model\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, deterministic=False):\n",
    "        state, _ = self.env.reset()\n",
    "        done = False\n",
    "        trajectory = []\n",
    "        step = 0\n",
    "        while not done:\n",
    "            # import pdb; pdb.set_trace()\n",
    "            state = torch.cat([state[\"state\"], state[\"action_mask\"]], dim=0).float().to(self.policy_n_value.device)\n",
    "            if not deterministic:\n",
    "                action, log_prob, _, value = self.policy_n_value.get_action_and_value(state.unsqueeze(0))\n",
    "            else:\n",
    "                action, log_prob = self.policy_model.act(state, deterministic=True)\n",
    "                value = self.value_model(state.unsqueeze(0))\n",
    "            next_state, reward, done, truncated, info = self.env.step(action.item())\n",
    "            done = done or truncated\n",
    "            trajectory.append((state, action, reward, log_prob, value))\n",
    "            state = next_state\n",
    "        return trajectory\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, env: DebugEnvironment, policy_n_value: PolicyValue, logger: Logger, gamma: float = 0.99, lam: float = 0.95, lr: float = 1e-4):\n",
    "        self.env = env\n",
    "        self.policy_n_value = policy_n_value\n",
    "        self.learner = RLLearner(policy_n_value, gamma=gamma, lam=lam, lr=lr, device=policy_n_value.device)\n",
    "        self.rollout = PolicyValueRollout(env, policy_n_value)\n",
    "        self.logger = logger\n",
    "        self.best_score = -1e20\n",
    "        self.sparsities = None\n",
    "\n",
    "    def __call__(self, num_iters:int=100):\n",
    "        for iter in range(num_iters):\n",
    "            start_time = time.time()\n",
    "            trajectories = [self.rollout() for _ in range(1)]\n",
    "            learner_results = self.learner(trajectories)\n",
    "            with torch.no_grad():\n",
    "                # trj =  self.rollout(deterministic=True)\n",
    "                trj = trajectories[0]\n",
    "                rew = sum(tran[2] for tran in trj)\n",
    "                if rew > self.best_score:\n",
    "                    self.best_score = rew\n",
    "                    torch.save(self.policy_n_value.policy_model.state_dict(), \"best_policy.pt\")\n",
    "                    self.sparsities = self.env.layer_sparsities\n",
    "                    print(f\"New best model saved with score {self.best_score} | Overall Sparsity: {np.mean(self.sparsities):.2f}\")\n",
    "            end_time = time.time()\n",
    "            loss = learner_results[\"learner/losses/policy_loss\"]\n",
    "            self.logger.log({**learner_results, \"Score\": rew}, step=learner_results[\"global_step\"])\n",
    "            print(f\"Iteration {iter+1}/{num_iters}, Loss: {loss:.4f}, Rew: {rew:.2f}, Global Step: {learner_results['global_step']}, Time: {end_time - start_time:.2f}s\")\n",
    "            del trajectories, trj\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b69a8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FineWeb-Edu v2\n",
      "Total tokens loaded: 524288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 56.12it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mldfrancis\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/esie/notebooks/wandb/run-20251006_100548-i2xybvdu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ldfrancis/RLPress/runs/i2xybvdu' target=\"_blank\">eternal-valley-248</a></strong> to <a href='https://wandb.ai/ldfrancis/RLPress' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ldfrancis/RLPress' target=\"_blank\">https://wandb.ai/ldfrancis/RLPress</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ldfrancis/RLPress/runs/i2xybvdu' target=\"_blank\">https://wandb.ai/ldfrancis/RLPress/runs/i2xybvdu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 51.59it/s]\n",
      "/tmp/ipykernel_59567/1240118773.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  states.append(torch.tensor(state).to(device))\n",
      "/tmp/ipykernel_59567/1240118773.py:143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  actions.append(torch.tensor(action).to(device))\n",
      "/tmp/ipykernel_59567/1240118773.py:145: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  log_probs.append(torch.tensor(log_prob).to(device))\n",
      "/tmp/ipykernel_59567/1240118773.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  values.append(torch.tensor(value).to(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score -18.52937126159668 | Overall Sparsity: 0.52\n",
      "Iteration 1/10, Loss: -0.0872, Rew: -18.53, Global Step: 32, Time: 39.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 54.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2/10, Loss: -0.0546, Rew: -86.03, Global Step: 64, Time: 36.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 51.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3/10, Loss: -0.0164, Rew: -20.20, Global Step: 96, Time: 32.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 52.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4/10, Loss: -0.0179, Rew: -50.79, Global Step: 128, Time: 36.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 50.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score -18.324491500854492 | Overall Sparsity: 0.50\n",
      "Iteration 5/10, Loss: -0.0284, Rew: -18.32, Global Step: 160, Time: 38.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 52.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6/10, Loss: -0.0268, Rew: -160.78, Global Step: 192, Time: 33.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 50.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score -12.37375545501709 | Overall Sparsity: 0.50\n",
      "Iteration 7/10, Loss: -0.0259, Rew: -12.37, Global Step: 224, Time: 37.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 52.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with score -11.55493450164795 | Overall Sparsity: 0.50\n",
      "Iteration 8/10, Loss: -0.0158, Rew: -11.55, Global Step: 256, Time: 43.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 51.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9/10, Loss: -0.0123, Rew: -24.63, Global Step: 288, Time: 41.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 51.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10/10, Loss: -0.0186, Rew: -13.75, Global Step: 320, Time: 37.37s\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "S = 3\n",
    "# env = gym.make(\"CartPole-v1\", max_episode_steps=200) #DebugEnvironment()\n",
    "# env = DebugEnvironment()\n",
    "env = Environment(model_name=\"meta-llama/Llama-2-7b-hf\", num_samples=128, sequence_length=4096, target_sparsity=0.5)\n",
    "\n",
    "policy_model = Policy(state_size=S+N, action_size=N, device=device)\n",
    "value_model = Value(state_size=S+N, device=device)\n",
    "\n",
    "policy_n_value = PolicyValue(policy_model, value_model)\n",
    "policy_n_value.to(device)\n",
    "\n",
    "logger = WandBLogger(entity=\"ldfrancis\", project_name=\"RLPress\")\n",
    "trainer = Trainer(env, policy_n_value, logger=logger, gamma=0.99, lam=0.95, lr=1e-3)\n",
    "# trainer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f75f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 51.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Action 7\n",
      "Step 2: Action 7\n",
      "Step 3: Action 7\n",
      "Step 4: Action 7\n",
      "Step 5: Action 7\n",
      "Step 6: Action 7\n",
      "Step 7: Action 7\n",
      "Step 8: Action 7\n",
      "Step 9: Action 7\n",
      "Step 10: Action 1\n",
      "Step 11: Action 7\n",
      "Step 12: Action 1\n",
      "Step 13: Action 1\n",
      "Step 14: Action 1\n",
      "Step 15: Action 1\n",
      "Step 16: Action 1\n",
      "Step 17: Action 1\n",
      "Step 18: Action 1\n",
      "Step 19: Action 1\n",
      "Step 20: Action 1\n",
      "Step 21: Action 1\n",
      "Step 22: Action 1\n",
      "Step 23: Action 1\n",
      "Step 24: Action 7\n",
      "Step 25: Action 8\n",
      "Step 26: Action 9\n",
      "Step 27: Action 9\n",
      "Step 28: Action 9\n",
      "Step 29: Action 8\n",
      "Step 30: Action 9\n",
      "Step 31: Action 9\n",
      "Step 32: Action 9\n",
      "Achieved Score: -31.919588088989258\n"
     ]
    }
   ],
   "source": [
    "policy_model.load_state_dict(torch.load(\"best_policy.pt\"))\n",
    "state, _ = env.reset()\n",
    "done = False\n",
    "score = 0\n",
    "step = 0\n",
    "sparsities = []\n",
    "while not done:\n",
    "    x = torch.cat([state[\"state\"], state[\"action_mask\"]], dim=0).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        dist = policy_model(x.unsqueeze(0))\n",
    "        action = dist.mode\n",
    "    next_state, reward, done, truncated, info = env.step(action.item())\n",
    "    done = done or truncated\n",
    "    state = next_state\n",
    "    score += reward\n",
    "    step += 1\n",
    "    print(f\"Step {step}: Action {action.item()}\")\n",
    "print(f\"Achieved Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4be610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(env.layer_sparsities)/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd58b843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 51.65it/s]\n"
     ]
    }
   ],
   "source": [
    "policy_model.load_state_dict(torch.load(\"best_policy.pt\"))\n",
    "state, _ = env.reset()\n",
    "done = False\n",
    "score = 0\n",
    "step = 0\n",
    "sparsities = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ab6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.cat([state[\"state\"], state[\"action_mask\"]], dim=0).float().to(device)\n",
    "with torch.no_grad():\n",
    "    dist = policy_model(x.unsqueeze(0))\n",
    "    action = dist.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df4ffcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"action_mask\"], action.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b483cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state, reward, done, truncated, info = env.step(action.item())\n",
    "state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5efa0ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.decoder.layers.0.self_attn.k_proj\n",
      "model.decoder.layers.0.self_attn.v_proj\n",
      "model.decoder.layers.0.self_attn.q_proj\n",
      "model.decoder.layers.0.self_attn.out_proj\n",
      "model.decoder.layers.0.fc1\n",
      "model.decoder.layers.0.fc2\n",
      "model.decoder.layers.1.self_attn.k_proj\n",
      "model.decoder.layers.1.self_attn.v_proj\n",
      "model.decoder.layers.1.self_attn.q_proj\n",
      "model.decoder.layers.1.self_attn.out_proj\n",
      "model.decoder.layers.1.fc1\n",
      "model.decoder.layers.1.fc2\n",
      "model.decoder.layers.2.self_attn.k_proj\n",
      "model.decoder.layers.2.self_attn.v_proj\n",
      "model.decoder.layers.2.self_attn.q_proj\n",
      "model.decoder.layers.2.self_attn.out_proj\n",
      "model.decoder.layers.2.fc1\n",
      "model.decoder.layers.2.fc2\n",
      "model.decoder.layers.3.self_attn.k_proj\n",
      "model.decoder.layers.3.self_attn.v_proj\n",
      "model.decoder.layers.3.self_attn.q_proj\n",
      "model.decoder.layers.3.self_attn.out_proj\n",
      "model.decoder.layers.3.fc1\n",
      "model.decoder.layers.3.fc2\n",
      "model.decoder.layers.4.self_attn.k_proj\n",
      "model.decoder.layers.4.self_attn.v_proj\n",
      "model.decoder.layers.4.self_attn.q_proj\n",
      "model.decoder.layers.4.self_attn.out_proj\n",
      "model.decoder.layers.4.fc1\n",
      "model.decoder.layers.4.fc2\n",
      "model.decoder.layers.5.self_attn.k_proj\n",
      "model.decoder.layers.5.self_attn.v_proj\n",
      "model.decoder.layers.5.self_attn.q_proj\n",
      "model.decoder.layers.5.self_attn.out_proj\n",
      "model.decoder.layers.5.fc1\n",
      "model.decoder.layers.5.fc2\n",
      "model.decoder.layers.6.self_attn.k_proj\n",
      "model.decoder.layers.6.self_attn.v_proj\n",
      "model.decoder.layers.6.self_attn.q_proj\n",
      "model.decoder.layers.6.self_attn.out_proj\n",
      "model.decoder.layers.6.fc1\n",
      "model.decoder.layers.6.fc2\n",
      "model.decoder.layers.7.self_attn.k_proj\n",
      "model.decoder.layers.7.self_attn.v_proj\n",
      "model.decoder.layers.7.self_attn.q_proj\n",
      "model.decoder.layers.7.self_attn.out_proj\n",
      "model.decoder.layers.7.fc1\n",
      "model.decoder.layers.7.fc2\n",
      "model.decoder.layers.8.self_attn.k_proj\n",
      "model.decoder.layers.8.self_attn.v_proj\n",
      "model.decoder.layers.8.self_attn.q_proj\n",
      "model.decoder.layers.8.self_attn.out_proj\n",
      "model.decoder.layers.8.fc1\n",
      "model.decoder.layers.8.fc2\n",
      "model.decoder.layers.9.self_attn.k_proj\n",
      "model.decoder.layers.9.self_attn.v_proj\n",
      "model.decoder.layers.9.self_attn.q_proj\n",
      "model.decoder.layers.9.self_attn.out_proj\n",
      "model.decoder.layers.9.fc1\n",
      "model.decoder.layers.9.fc2\n",
      "model.decoder.layers.10.self_attn.k_proj\n",
      "model.decoder.layers.10.self_attn.v_proj\n",
      "model.decoder.layers.10.self_attn.q_proj\n",
      "model.decoder.layers.10.self_attn.out_proj\n",
      "model.decoder.layers.10.fc1\n",
      "model.decoder.layers.10.fc2\n",
      "model.decoder.layers.11.self_attn.k_proj\n",
      "model.decoder.layers.11.self_attn.v_proj\n",
      "model.decoder.layers.11.self_attn.q_proj\n",
      "model.decoder.layers.11.self_attn.out_proj\n",
      "model.decoder.layers.11.fc1\n",
      "model.decoder.layers.11.fc2\n",
      "lm_head\n"
     ]
    }
   ],
   "source": [
    "for n,m in model.named_modules():\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a15cc554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FineWeb-Edu v2\n",
      "Total tokens loaded: 524288\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/opt-125m\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, dtype=torch.float16, device_map=\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "save_dir = f\"logs/sparse_weights/{model_name.split('/')[-1]}\"\n",
    "num_samples = 128\n",
    "sequence_length = 4096\n",
    "sparsity_ratios = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "num_tokens = num_samples * sequence_length\n",
    "calib_data = get_fineweb_edu(num_tokens, sequence_length, tokenizer, train=True)\n",
    "_, test_data = get_w2_data(num_samples, sequence_length, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9acf36f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.438, 0.442, 0.446, 0.45, 0.454, 0.458, 0.462, 0.466, 0.47, 0.474, 0.478, 0.482, 0.486, 0.49, 0.494, 0.498, 0.502, 0.506, 0.51, 0.514, 0.518, 0.522, 0.526, 0.53, 0.534, 0.538, 0.542, 0.546, 0.55, 0.554, 0.558, 0.562]\n"
     ]
    }
   ],
   "source": [
    "s = []\n",
    "S = 0.5\n",
    "b = 0.004\n",
    "for i in range(1, 33):\n",
    "    s.append(S - (b*(32-1))/2 + b*(i-1))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f82ca5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading calibration data\n",
      "dataset loading complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [0,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [1,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [2,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [3,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [4,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [5,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [6,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [7,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [8,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [9,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [10,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [11,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [12,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [13,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [14,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [15,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [16,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [17,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [18,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [19,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [20,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [21,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [22,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [23,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [24,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [25,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [26,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [27,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [28,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [29,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [30,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [2257,0,0], thread: [31,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprune_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalib_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta3\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_sparsegpt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/esie/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/esie/notebooks/utils.py:289\u001b[0m, in \u001b[0;36mprune_default\u001b[0;34m(model, calib_data, sparsity_ratios, theta1, theta2, theta3, is_sparsegpt, device, save_dir)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset loading complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 289\u001b[0m     inps, outs, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_calibration_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalib_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m layers \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlayers\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity_ratios) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/esie/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/esie/notebooks/utils.py:268\u001b[0m, in \u001b[0;36mprepare_calibration_input\u001b[0;34m(model, calib_data, device)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m calib_data:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m \n",
      "File \u001b[0;32m~/.conda/envs/esie/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/esie/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/esie/lib/python3.10/site-packages/transformers/utils/generic.py:918\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[0;32m--> 918\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    920\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/.conda/envs/esie/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:818\u001b[0m, in \u001b[0;36mOPTForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, position_ids, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 818\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    835\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/esie/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/esie/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/esie/lib/python3.10/site-packages/transformers/utils/generic.py:918\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[0;32m--> 918\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    920\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/.conda/envs/esie/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:648\u001b[0m, in \u001b[0;36mOPTDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, position_ids, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dropout_probability \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerdrop:\n\u001b[1;32m    646\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 648\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.conda/envs/esie/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/esie/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/esie/notebooks/utils.py:259\u001b[0m, in \u001b[0;36mprepare_calibration_input.<locals>.Catcher.forward\u001b[0;34m(self, inp, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 259\u001b[0m     \u001b[43minps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m inp\n\u001b[1;32m    260\u001b[0m     cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    261\u001b[0m     cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
      "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "prune_default(model, calib_data, s, theta1=0, theta2=0, theta3=1, is_sparsegpt=False, device=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e24661be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4998888788478715"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsities = [np.mean([(l.weight.data == 0).float().mean().item() for l in layer.modules() if isinstance(l, nn.Linear)]).item() for layer in model.model.layers]\n",
    "np.mean(sparsities).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ce9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_default(model, calib_data, sparsity_ratios, theta1=0.42, theta2=0.51, theta3=0.38, is_sparsegpt=True, device=torch.device(\"cuda:0\"), save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0667c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.3823676109313965"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ppl(model, test_data, sequence_length, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fa0d7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTConfig {\n",
       "  \"_remove_final_layer_norm\": false,\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"relu\",\n",
       "  \"architectures\": [\n",
       "    \"OPTForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 2,\n",
       "  \"do_layer_norm_before\": true,\n",
       "  \"dropout\": 0.1,\n",
       "  \"dtype\": \"float16\",\n",
       "  \"enable_bias\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"ffn_dim\": 3072,\n",
       "  \"hidden_size\": 768,\n",
       "  \"init_std\": 0.02,\n",
       "  \"layer_norm_elementwise_affine\": true,\n",
       "  \"layerdrop\": 0.0,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"opt\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"prefix\": \"</s>\",\n",
       "  \"transformers_version\": \"4.57.0\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 50272,\n",
       "  \"word_embed_proj_dim\": 768\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da7ed1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454ef62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_dir = os.path.join(f\"logs/sparse_weights/{model_name.split('/')[-1]}\", \"sparsegpt\")\n",
    "layer_sparsity_ratios = [0.6]*model.config.num_hidden_layers\n",
    "load_layers(model, layer_sparsity_ratios=layer_sparsity_ratios, dir=weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e719476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000000000000000000000000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "RLPress"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
